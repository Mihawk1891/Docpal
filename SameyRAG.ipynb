{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy3/NRuub+0BCU2ZY6b+E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import google.generativeai as genai\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from rank_bm25 import BM25Okapi\n",
        "from langchain_community.retrievers import BM25Retriever"
      ],
      "metadata": {
        "id": "ddad_18cTYIS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"API_KEY\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "96zHvL01XCxN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_split_documents(file_paths):\n",
        "    documents = []\n",
        "    for file_path in file_paths:\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        documents.extend(loader.load())\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    return text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "M2dNho-8sw7R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_store(documents):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    return FAISS.from_documents(documents, embeddings)"
      ],
      "metadata": {
        "id": "f8QRgt90wv4f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bm25_retriever(documents):\n",
        "    return BM25Retriever.from_documents(documents)"
      ],
      "metadata": {
        "id": "jXHalot3w21C"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_retriever(vector_store, documents, method=\"dense\"):\n",
        "    if method == \"dense\":\n",
        "        return vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "    elif method == \"bm25\":\n",
        "        return create_bm25_retriever(documents)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid retrieval method. Choose 'dense' or 'bm25'.\")"
      ],
      "metadata": {
        "id": "A-F_lr7Rw2wE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "User Query: {user_input}\n",
        "\n",
        "Relevant Corpus Data:\n",
        "{context}\n",
        "\n",
        "You are a document analysis assistant. Based on the User Query and the relevant Corpus data, please provide a detailed and accurate response. If you need any clarification or additional information, please ask.\n",
        "\n",
        "The answer should be in points and then subpoints. Use paragraphs only when necessary.\n",
        "\n",
        "Focus solely on the document content to answer the user's question. But in case user wants some relevant knowledge releated to corpus then allow the outside access.  If there is a user query that cannot be answered using the provided context, respond with 'Please ask questions about the Corpus'.\n",
        "\n",
        "Do not repeat the user's question. If the user's query is vague, provide answers and also suggest more specific questions.\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "aeyrNf5Pw2YR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "HkMg2q2ozknC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rag_chain(retriever):\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\n",
        "            \"context\": lambda x: format_docs(retriever.get_relevant_documents(x[\"user_input\"])),\n",
        "            \"user_input\": lambda x: x[\"user_input\"],\n",
        "            \"chat_history\": lambda x: x[\"chat_history\"]\n",
        "        }\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return rag_chain\n"
      ],
      "metadata": {
        "id": "TqS42WoJxE67"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load and process documents\n",
        "    file_paths = [\"Corpus.pdf\"]  # Add more file paths as needed\n",
        "    documents = load_and_split_documents(file_paths)\n",
        "\n",
        "    # Create vector store and retriever\n",
        "    vector_store = create_vector_store(documents)\n",
        "    retriever = create_retriever(vector_store, documents, method=\"dense\")  # Change to \"bm25\" if needed\n",
        "\n",
        "    # Create RAG chain\n",
        "    rag_chain = create_rag_chain(retriever)\n",
        "\n",
        "    # Chat loop\n",
        "    chat_history = \"\"\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = rag_chain.invoke({\"user_input\": user_input, \"chat_history\": chat_history})\n",
        "            print(\"AI:\", response)\n",
        "\n",
        "            chat_history += f\"Human: {user_input}\\nAI: {response}\\n\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0PFXhRjxIq4",
        "outputId": "42edd38f-d5c9-40dd-d206-fdf2899f4ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is hover?\n",
            "AI: HOVER stands for HOppyVERification. Here are some key points about it:\n",
            "\n",
            "* **Purpose:** HOVER is a dataset designed for testing and improving \"many-hop\" evidence extraction and fact verification in AI models. \n",
            "    * This means it challenges models to make connections across multiple pieces of information, rather than finding simple, direct matches.\n",
            "\n",
            "* **Structure:**\n",
            "    *  HOVER presents claims that need to be verified.\n",
            "    *  Evidence for these claims is spread across multiple Wikipedia articles (up to four).\n",
            "    *  The connections between the claim and the evidence form \"reasoning graphs\" of various complexities.\n",
            "\n",
            "* **Challenges:**\n",
            "    *  HOVER claims often require information from several sources, making it harder for models to find all the necessary evidence.\n",
            "    *  The claims are written in a way that avoids simple word matching, forcing models to understand the meaning and relationships between concepts.\n",
            "    *  Many claims are multi-sentence, adding the difficulty of understanding long-range dependencies in language (like how pronouns refer to earlier words).\n",
            "\n",
            "* **Significance:** HOVER is significantly larger and more complex than many prior datasets in this area. This makes it a valuable tool for driving the development of AI systems that can perform more sophisticated reasoning and fact-checking. \n",
            "\n"
          ]
        }
      ]
    }
  ]
}