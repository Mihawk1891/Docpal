# Samey AI Assessment Solution By Pranav Bansode.

## • Problem_1 (Only Explorer Mode) [Problem_1.py]
### Solution Overview

This solution creates an interactive web application combining natural language processing (NLP) and machine learning techniques to enhance sentiment analysis and psychological insights from text and audio inputs. The application leverages various NLP libraries and machine learning algorithms to comprehensively analyze emotional states and psychological conditions based on user-provided text or audio data.

##3 Key Features of this solution

- Sentiment Analysis: Determines the overall sentiment of text input using advanced NLP techniques.
- Psychological State Classification: Identifies psychological states such as joy, anger, confusion, excitement, sadness, anxiety, calmness, and boredom.
- Entity Extraction: Detects named entities in the input text.
- Audio Processing: Transcribes audio files into text and analyzes tempo and pitch characteristics.
- Interactive Visualization: Displays sentiment analysis results in a bar chart.
- User-Friendly Interface: Utilizes Streamlit for easy interaction and visualization.

### Technologies Used

- Streamlit: For creating the interactive web interface
- NLTK: Natural Language Toolkit for text processing and sentiment analysis
- spaCy: Modern natural language understanding library
- scikit-learn: Machine learning algorithms for classification
- TextBlob: Simple API for diving into common NLP tasks
- Librosa: Audio analysis library
- Speech Recognition: For transcribing audio files

### Solution Structure

The project consists of several key components:

1. EnhancedAnalyzer Class: Centralizes all analysis functionality
2. Text Analysis Module: Handles sentiment scoring, subjectivity detection, and psychological state classification
3. Audio Processing Module: Transcribes audio and extracts tempo and pitch features
4. Visualization Module: Creates interactive charts using Plotly
5. Main Application: Manages user input selection and results display

### Implementation Highlights

- Custom Psychological State Classifier: Trains a machine learning model to identify specific emotional states
- Advanced Sentiment Scoring: Uses compound scores for nuanced sentiment analysis
- Entity Extraction: Leverages spaCy's named entity recognition capabilities
- Audio Feature Extraction: Analyzes tempo and pitch characteristics of speech

### Potential Applications

- Mental Health Support Systems
- Customer Service Analytics
- Social Media Monitoring Tools
- Content Creation Assistance

### Future Improvements

- Integration with additional NLP libraries for enhanced feature extraction
- Development of more sophisticated machine learning models for improved accuracy
- Expansion to support multiple languages
- Incorporation of real-time feedback mechanisms

### Getting Started

To run the application locally:

1. Install required dependencies using pip:
   ```
   pip install streamlit nltk spacy scikit-learn textblob librosa speech_recognition plotly
   ```

2. Download necessary NLTK data:
   ```
   python -m nltk.downloader vader_lexicon punkt averaged_perceptron_tagger maxent_ne_chunker words
   ```

3. Load the spaCy English model:
   ```
   python -m spacy download en_core_web_sm
   ```

4. Run the application:
   ```
   problem_1.py
   ```





## • Problem_2 (SameyRAG.ipynb)

### Solution Overview

This solution combines the strengths of traditional information retrieval systems with advanced language models. Our RAG implementation allows users to query a corpus of documents and receive responses generated by an LLM, augmented with relevant retrieved information.

Key features of this project:

- Supports both dense vector retrieval and BM25-based retrieval methods
- Integrates with Google Generative AI for LLM capabilities
- Implements a modular design for easy customization and experimentation
- Provides a chat interface for user interaction

### How It Works

Our RAG system operates as follows:

1. **Document Loading**: PDF files are loaded and processed using PyPDFLoader and RecursiveCharacterTextSplitter.

2. **Vector Store Creation**: Documents are converted into numerical embeddings using GoogleGenerativeAIEmbeddings and stored in a FAISS vector store.

3. **Retriever Selection**: Users can choose between dense retrieval and BM25 retrieval methods.

4. **Query Processing**: When a user inputs a query, our system retrieves relevant documents from the chosen vector store.

5. **Response Generation**: The retrieved documents are passed along with the original query to the LLM (Google Generative AI).

6. **Response Formatting**: The final response is formatted according to the prompt template.

### Technical Details

- **Retrieval Methods**: 
  - Dense retrieval uses FAISS for efficient similarity searches.
  - BM25Okapi provides relevance-ranked document retrieval.

- **LLM Integration**: 
  - Utilizes ChatGoogleGenerativeAI for generating responses.
  - Temperature control is implemented for fine-tuning output quality.

- **Modular Design**: 
  - Separate functions for loading documents, creating vector stores, retrievers, and RAG chains.
  - Allows for easy modification and extension of individual components.

### Usage

1. Clone the repository:
   ```
   git clone https://github.com/[your-username]/[repository-name].git
   ```

2. Set up the Python environment:
   - Navigate to the `python_env` folder
   - Import the `NLP.yml` file to create a dedicated Python environment

3. Configure API keys:
   - Set your Google API key in the `os.environ["GOOGLE_API_KEY"]`
   - Add your OpenAI API key in the `common/openAI.env` file

4. Run the main SameyRAG.ipynb file:
   ```
   SameyRAG.ipynb
   ```
   This will start the chat interface where you can interact with the RAG system.


1. Run the main script to start the chat interface.
2. Type your queries or questions.
3. The system will retrieve relevant documents and generate responses based on those documents and your input.





## • Problem_3 (problem_3.py)

### Solution Overview

The solution implements an optimized Large Language Model (LLM) based document analysis system. It leverages various techniques to improve performance, including hybrid vector search, semantic caching, dynamic batching, and potential embedding quantization. The system processes PDF documents, extracts relevant information, and provides detailed analysis based on user queries.

### Key Components

1. **Document Loading and Splitting**
   - Uses PyPDFLoader to load PDF documents
   - Employs RecursiveCharacterTextSplitter for efficient document splitting

2. **Embedding Generation**
   - Utilizes SentenceTransformer for generating high-quality sentence embeddings
   - Integrates Google Generative AI for text generation capabilities

3. **Vector Search Optimization**
   - Implements hybrid vector search using HNSW algorithm
   - Employs FAISS for efficient similarity search

4. **Query Processing and Batching**
   - Implements dynamic batching for asynchronous query processing
   - Uses asyncio for parallel execution of queries

5. **Semantic Caching**
   - Implements a caching mechanism using SentenceTransformer and FAISS
   - Stores and retrieves previously processed queries and their corresponding results

6. **Quantization of Embeddings**
   - Includes functions for quantizing and dequantizing embeddings
   - Potentially reduces memory usage and computational complexity

## Getting Started

To run this application locally:

1. Clone the repository
2. Install dependencies: `pip install -r requirements.txt`
3. Set environment variables (API_KEY, etc.)
4. Run the server: `python run_server.py`

To interact with the API:

- Send POST requests to `http://localhost:8000/query`
- Include query text in the request body

### Detailed Implementation

1. **Hybrid Vector Search Optimization**
   - Creates an HNSW index for efficient approximate nearest neighbor search
   - Uses hnswlib for building the HNSW index
   - Integrates with SentenceTransformer for embedding generation

2. **Semantic Caching Mechanism**
   - Implements a cache using SentenceTransformer and FAISS
   - Sets a similarity threshold (0.9) for result retrieval from the cache
   - Automatically refreshes the cache when it reaches capacity

3. **Dynamic Batching**
   - Uses asyncio.Queue for managing query batches
   - Implements timeout handling to prevent indefinite waiting
   - Processes queries in batches to optimize CPU utilization

4. **Embedding Quantization**
   - Provides functions for quantizing and dequantizing embeddings
   - Allows for potential reduction in memory usage and computational complexity

5. **API Integration**
   - Built using FastAPI for creating a RESTful API
   - Supports POST requests for querying the system

6. **LLM Integration**
   - Uses Google Generative AI for text generation capabilities
   - Configures the model with an API key for secure access

### Performance Enhancements

1. **Parallel Processing**: Utilizes asyncio for asynchronous processing of queries and batching.

2. **Efficient Document Loading**: Employs RecursiveCharacterTextSplitter for efficient document splitting.

3. **Vector Retrieval Efficiency**: Leverages FAISS for efficient similarity search and HNSW algorithm for approximate nearest neighbor search.

4. **Reduced Redundancy**: Implements semantic caching to reduce redundant computations for repeated queries.

5. **Asynchronous Execution**: Uses asyncio to manage concurrent processing of queries and batches.
